<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>ct: Derivatives/Jacobian/Linearization Tutorial</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ct
   &#160;<span id="projectnumber">v3.0</span>
   </div>
   <div id="projectbrief">Control Toolbox</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('core_tut_linearization.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Derivatives/Jacobian/Linearization Tutorial </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#core_tut_linearization_function">Jacobian/Derivative of a General Function</a></li>
<li class="level1"><a href="#core_tut_linearization_systems">Jacobian/Linearization of a Nonlinear System</a></li>
<li class="level1"><a href="#core_tut_linearization_scalar_templating">Templating your System or Function on the Scalar Type</a></li>
</ul>
</div>
<div class="textblock"><p>Often when working with a general nonlinear function <img class="formulaInl" alt="$ f(x) $" src="form_1.png"/> we are interested in its Jacobian (derivatives) <img class="formulaInl" alt="$ J = \frac{df}{dx} $" src="form_2.png"/>.</p>
<p>In order to compute this Jacobian, we are left with four methods</p><ol type="1">
<li>Numerical differentiation, e.g. <img class="formulaInl" alt="$ A = \frac{f(x+h,u) - f(x)}{h} $" src="form_3.png"/></li>
<li>Analytical, manually derivation</li>
<li>Symbolic math engine</li>
<li>Auto-Differentiation (with optional codegen)</li>
</ol>
<p>The different methods are summarized below:</p>
<table class="doxtable">
<tr>
<th>Derivative Method </th><th>Numerical Accuracy </th><th>Computation Speed </th><th>Setup Time </th><th>Error Safe  </th></tr>
<tr>
<td>Numeric Differentiation </td><td>- </td><td>- </td><td>+++ </td><td>+++ </td></tr>
<tr>
<td>Analytical Derivatives </td><td>+++ </td><td>++ </td><td>- </td><td>- </td></tr>
<tr>
<td>Symbolic Math Engine </td><td>+++ </td><td>+ </td><td>+ </td><td>++ </td></tr>
<tr>
<td>Automatic Differentiation </td><td>+++ </td><td>+ </td><td>++ </td><td>++ </td></tr>
<tr>
<td>Auto-Diff Code Generation </td><td>+++ </td><td>+++ </td><td>++ </td><td>++ </td></tr>
</table>
<p>Bottom line: Automatic Differentiation is the tool of choice for accurate, yet easy to setup derivatives. For best performance, Automatic Differentiation with code generation (Auto-Diff Codgen) should be used. <b>Auto-Diff Codegen is as accurate as analytical derivatives and equally fast if not faster!</b>. For more on this please refer to the following publications: <b>[giftthaler2017autodiff]</b> <b>[neunert:2016:derivatives]</b></p>
<dl class="section note"><dt>Note</dt><dd>Both Auto-Diff and Auto-Diff Codegen require you to template your function on the scalar type. Please see the tutorial <a class="el" href="core_tut_linearization.html#core_tut_linearization_scalar_templating">Templating your System or Function on the Scalar Type</a> for tips and tricks on how to do this easily!</dd></dl>
<h1><a class="anchor" id="core_tut_linearization_function"></a>
Jacobian/Derivative of a General Function</h1>
<p>In this tutorial, we will compute the Jacobian (derivative) of a general function using Auto-Diff Codegeneration. For this let's look at the unit test found in ct_core/test/math/JacobianCGTest.h</p>
<div class="fragment"><div class="line"><span class="comment">/**********************************************************************************************************************</span></div><div class="line"><span class="comment">This file is part of the Control Toolbox (https://adrlab.bitbucket.io/ct), copyright by ETH Zurich, Google Inc.</span></div><div class="line"><span class="comment">Licensed under Apache2 license (see LICENSE file in main directory)</span></div><div class="line"><span class="comment">**********************************************************************************************************************/</span></div><div class="line"><span class="preprocessor">#pragma once</span></div><div class="line"></div><div class="line"><span class="comment">// define the input and output sizes of the function</span></div><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> inDim = 3;   </div><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> outDim = 2;  </div><div class="line"></div><div class="line"><span class="keyword">typedef</span> DerivativesCppadJIT&lt;inDim, outDim&gt; derivativesCppadJIT;</div><div class="line"><span class="keyword">typedef</span> DerivativesCppadCG&lt;inDim, outDim&gt; derivativesCppadCG;</div><div class="line"><span class="keyword">typedef</span> DerivativesCppad&lt;inDim, outDim&gt; derivativesCppad;</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> SCALAR&gt;</div><div class="line">Eigen::Matrix&lt;SCALAR, outDim, 1&gt; testFunction(<span class="keyword">const</span> Eigen::Matrix&lt;SCALAR, inDim, 1&gt;&amp; x)</div><div class="line">{</div><div class="line">    Eigen::Matrix&lt;SCALAR, outDim, 1&gt; y;</div><div class="line"></div><div class="line">    y(0) = 3 * x(0) + 2 * x(0) * x(0) - x(1) * x(2);</div><div class="line">    y(1) = x(2) + x(1) + 3;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> y;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> SCALAR&gt;</div><div class="line">Eigen::Matrix&lt;SCALAR, outDim, inDim&gt; jacobianCheck(<span class="keyword">const</span> Eigen::Matrix&lt;SCALAR, inDim, 1&gt;&amp; x)</div><div class="line">{</div><div class="line">    Eigen::Matrix&lt;SCALAR, outDim, inDim&gt; jac;</div><div class="line"></div><div class="line">    jac &lt;&lt; 3 + 4 * x(0), -x(2), -x(1), 0, 1, 1;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> jac;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> SCALAR&gt;</div><div class="line">Eigen::Matrix&lt;SCALAR, inDim, inDim&gt; hessianCheck(<span class="keyword">const</span> Eigen::Matrix&lt;SCALAR, inDim, 1&gt;&amp; x,</div><div class="line">    <span class="keyword">const</span> Eigen::Matrix&lt;SCALAR, outDim, 1&gt;&amp; w)</div><div class="line">{</div><div class="line">    Eigen::Matrix&lt;SCALAR, inDim, inDim&gt; hes;</div><div class="line"></div><div class="line">    hes &lt;&lt; 4, 0, 0, 0, 0, -1, 0, -1, 0;</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> w(0) * hes;</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line">TEST(JacobianCGTest, ForwardZeroTest)</div><div class="line">{</div><div class="line">    <span class="keywordflow">try</span></div><div class="line">    {</div><div class="line">        <span class="comment">// create a function handle (also works for class methods, lambdas, function pointers, ...)</span></div><div class="line">        <span class="keyword">typename</span> derivativesCppadJIT::FUN_TYPE_CG f_cg = testFunction&lt;derivativesCppadJIT::CG_SCALAR&gt;;</div><div class="line">        <span class="keyword">typename</span> derivativesCppad::FUN_TYPE_AD f_ad = testFunction&lt;derivativesCppad::AD_SCALAR&gt;;</div><div class="line"></div><div class="line">        <span class="comment">// initialize the Auto-Diff Codegen Jacobian</span></div><div class="line">        derivativesCppadJIT jacCG(f_cg);</div><div class="line">        derivativesCppad jacAd(f_ad);</div><div class="line"></div><div class="line">        DerivativesCppadSettings settings;</div><div class="line">        settings.createForwardZero_ = <span class="keyword">true</span>;</div><div class="line">        settings.createJacobian_ = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">        <span class="comment">// create a random double vector</span></div><div class="line">        Eigen::VectorXd someVec(inDim);</div><div class="line">        someVec.setRandom();</div><div class="line"></div><div class="line">        <span class="comment">// test evaluation of forward zero before compilation</span></div><div class="line">        Eigen::VectorXd vecOut = jacAd.forwardZero(someVec);</div><div class="line"></div><div class="line">        <span class="comment">// compile the Jacobian</span></div><div class="line">        jacCG.compileJIT(settings, <span class="stringliteral">&quot;forwardZeroTestLib&quot;</span>);</div><div class="line"></div><div class="line">        <span class="comment">// test evaluation of forward zero after compilation</span></div><div class="line">        Eigen::VectorXd vecOut2 = jacCG.forwardZero(someVec);</div><div class="line"></div><div class="line">        <span class="comment">// verify the outputs</span></div><div class="line">        ASSERT_LT((vecOut - vecOut2).array().abs().maxCoeff(), 1e-10);</div><div class="line"></div><div class="line">    } <span class="keywordflow">catch</span> (std::exception&amp; e)</div><div class="line">    {</div><div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Exception thrown: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div><div class="line">        ASSERT_TRUE(<span class="keyword">false</span>);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line">TEST(JacobianCGTest, JITCompilationTest)</div><div class="line">{</div><div class="line">    <span class="keywordflow">try</span></div><div class="line">    {</div><div class="line">        <span class="comment">// create a function handle (also works for class methods, lambdas, function pointers, ...)</span></div><div class="line">        <span class="keyword">typename</span> derivativesCppadJIT::FUN_TYPE_CG f = testFunction&lt;derivativesCppadJIT::CG_SCALAR&gt;;</div><div class="line">        <span class="keyword">typename</span> derivativesCppad::FUN_TYPE_AD f_ad = testFunction&lt;derivativesCppad::AD_SCALAR&gt;;</div><div class="line"></div><div class="line">        <span class="comment">// initialize the Auto-Diff Codegen Jacobian</span></div><div class="line">        derivativesCppadJIT jacCG(f);</div><div class="line">        derivativesCppad jacAd(f_ad);</div><div class="line"></div><div class="line">        DerivativesCppadSettings settings;</div><div class="line">        settings.createJacobian_ = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">        <span class="comment">// compile the Jacobian</span></div><div class="line">        jacCG.compileJIT(settings, <span class="stringliteral">&quot;jacobianCGLib&quot;</span>);</div><div class="line"></div><div class="line">        <span class="comment">// create an input vector</span></div><div class="line">        Eigen::Matrix&lt;double, inDim, 1&gt; x;</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; 1000; i++)</div><div class="line">        {</div><div class="line">            <span class="comment">// create a random input</span></div><div class="line">            x.setRandom();</div><div class="line"></div><div class="line">            <span class="comment">// verify agains the analytical Jacobian</span></div><div class="line">            ASSERT_LT((jacCG.jacobian(x) - jacobianCheck(x)).array().abs().maxCoeff(), 1e-10);</div><div class="line">            ASSERT_LT((jacAd.jacobian(x) - jacobianCheck(x)).array().abs().maxCoeff(), 1e-10);</div><div class="line">            ASSERT_LT((jacCG.jacobian(x) - jacAd.jacobian(x)).array().abs().maxCoeff(), 1e-10);</div><div class="line">        }</div><div class="line">    } <span class="keywordflow">catch</span> (std::exception&amp; e)</div><div class="line">    {</div><div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Exception thrown: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div><div class="line">        ASSERT_TRUE(<span class="keyword">false</span>);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line">TEST(HessianCGTest, JITHessianTest)</div><div class="line">{</div><div class="line">    <span class="keywordflow">try</span></div><div class="line">    {</div><div class="line">        <span class="keyword">typename</span> derivativesCppadJIT::FUN_TYPE_CG f = testFunction&lt;derivativesCppadJIT::CG_SCALAR&gt;;</div><div class="line">        <span class="keyword">typename</span> derivativesCppad::FUN_TYPE_AD f_ad = testFunction&lt;derivativesCppad::AD_SCALAR&gt;;</div><div class="line"></div><div class="line">        derivativesCppadJIT hessianCg(f);</div><div class="line">        derivativesCppad hessianAd(f_ad);</div><div class="line"></div><div class="line">        DerivativesCppadSettings settings;</div><div class="line">        settings.createHessian_ = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">        hessianCg.compileJIT(settings, <span class="stringliteral">&quot;hessianCGLib&quot;</span>);</div><div class="line"></div><div class="line">        Eigen::Matrix&lt;double, inDim, 1&gt; x;</div><div class="line">        Eigen::Matrix&lt;double, outDim, 1&gt; w;</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; 1000; ++i)</div><div class="line">        {</div><div class="line">            x.setRandom();</div><div class="line">            w.setRandom();</div><div class="line"></div><div class="line">            ASSERT_LT((hessianCg.hessian(x, w) - hessianCheck(x, w)).array().abs().maxCoeff(), 1e-10);</div><div class="line">            ASSERT_LT((hessianAd.hessian(x, w) - hessianCheck(x, w)).array().abs().maxCoeff(), 1e-10);</div><div class="line">            ASSERT_LT((hessianCg.hessian(x, w) - hessianAd.hessian(x, w)).array().abs().maxCoeff(), 1e-10);</div><div class="line">        }</div><div class="line"></div><div class="line"></div><div class="line">    } <span class="keywordflow">catch</span> (std::exception&amp; e)</div><div class="line">    {</div><div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Exception thrown: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div><div class="line">        ASSERT_TRUE(<span class="keyword">false</span>);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line">TEST(JacobianCGTest, JITCloneTest)</div><div class="line">{</div><div class="line">    <span class="keywordflow">try</span></div><div class="line">    {</div><div class="line">        <span class="keyword">typename</span> derivativesCppadJIT::FUN_TYPE_CG f = testFunction&lt;derivativesCppadJIT::CG_SCALAR&gt;;</div><div class="line">        <span class="keyword">typename</span> derivativesCppad::FUN_TYPE_AD f_ad = testFunction&lt;derivativesCppad::AD_SCALAR&gt;;</div><div class="line"></div><div class="line">        <span class="comment">// initialize the Auto-Diff Codegen Jacobian</span></div><div class="line">        std::shared_ptr&lt;derivativesCppadJIT&gt; jacCG(<span class="keyword">new</span> derivativesCppadJIT(f));</div><div class="line">        std::shared_ptr&lt;derivativesCppad&gt; jacAd(<span class="keyword">new</span> derivativesCppad(f_ad));</div><div class="line"></div><div class="line">        DerivativesCppadSettings settings;</div><div class="line">        settings.createJacobian_ = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">        <span class="comment">// compile the Jacobian</span></div><div class="line">        jacCG-&gt;compileJIT(settings, <span class="stringliteral">&quot;jacobianCGLib&quot;</span>);</div><div class="line"></div><div class="line">        <span class="comment">// create an input vector</span></div><div class="line">        Eigen::Matrix&lt;double, inDim, 1&gt; x;</div><div class="line"></div><div class="line">        std::shared_ptr&lt;derivativesCppadJIT&gt; jacCG_cloned(jacCG-&gt;clone());</div><div class="line"></div><div class="line">        <span class="comment">// make sure the underlying dynamic libraries are not identical (dynamic library cloned correctly)</span></div><div class="line">        <span class="keywordflow">if</span> (jacCG_cloned-&gt;getDynamicLib() == jacCG-&gt;getDynamicLib())</div><div class="line">        {</div><div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;FATAL ERROR: dynamic library not cloned correctly in JIT.&quot;</span> &lt;&lt; std::endl;</div><div class="line">            ASSERT_TRUE(<span class="keyword">false</span>);</div><div class="line">        }</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; 100; i++)</div><div class="line">        {</div><div class="line">            <span class="comment">// create a random input</span></div><div class="line">            x.setRandom();</div><div class="line"></div><div class="line">            <span class="comment">// verify agains the analytical Jacobian</span></div><div class="line">            ASSERT_LT((jacCG_cloned-&gt;jacobian(x) - jacobianCheck(x)).array().abs().maxCoeff(), 1e-10);</div><div class="line">            ASSERT_LT((jacCG_cloned-&gt;jacobian(x) - jacAd-&gt;jacobian(x)).array().abs().maxCoeff(), 1e-10);</div><div class="line">        }</div><div class="line">    } <span class="keywordflow">catch</span> (std::exception&amp; e)</div><div class="line">    {</div><div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Exception thrown: &quot;</span> &lt;&lt; e.what() &lt;&lt; std::endl;</div><div class="line">        ASSERT_TRUE(<span class="keyword">false</span>);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// /*!</span></div><div class="line"><span class="comment">//  * Test for writing the codegenerated Jacobian to file</span></div><div class="line"><span class="comment">//  */</span></div><div class="line">TEST(JacobianCGTest, CodegenTest)</div><div class="line">{</div><div class="line">    <span class="comment">// create a function handle (also works for class methods, lambdas, function pointers, ...)</span></div><div class="line">    <span class="keyword">typename</span> derivativesCppadCG::FUN_TYPE_CG f = testFunction&lt;derivativesCppadCG::CG_SCALAR&gt;;</div><div class="line"></div><div class="line">    <span class="comment">// initialize the Auto-Diff Codegen Jacobian</span></div><div class="line">    derivativesCppadCG jacCG(f);</div><div class="line"></div><div class="line">    <span class="comment">// generate code for the Jacobian, similar to jacobianCheck()</span></div><div class="line">    jacCG.generateJacobianSource(<span class="stringliteral">&quot;TestJacobian&quot;</span>);</div><div class="line"></div><div class="line">    <span class="comment">// generate code for the actual function, will evaluate to the same as testFunction()</span></div><div class="line">    jacCG.generateForwardZeroSource(<span class="stringliteral">&quot;TestForwardZero&quot;</span>);</div><div class="line"></div><div class="line">    jacCG.generateHessianSource(<span class="stringliteral">&quot;TestHessian&quot;</span>);</div><div class="line">}</div></div><!-- fragment --><p>So what do we see here? In the first test, even though we do code generation, we can evaluate the Jacobian at runtime without recompiling our code. The code gets compiled in the background. This gives maximum speed while maintaining flexibility. For simple functions this process is very fast. However, what if our function is more complex? In this case, the second tests shows how to generate source code and actually write it to file.</p>
<p>But what is this ct::core::JacobianCG::generateForwardZeroCode()? Well it generates code for the original function. So in the end, it regenerates the function. But why is this even relavant? For such a simple example as here, there is probably not a lot of difference. However, for more complex equations, a regenerated function can be faster by up to 2x or more. The reason for that is that Auto-Diff builds an expression graph that can optimize the original function. Since it is case dependent whether you gain speed or not, you will have to try it out.</p>
<h1><a class="anchor" id="core_tut_linearization_systems"></a>
Jacobian/Linearization of a Nonlinear System</h1>
<p>Often when dealing with nonlinear systems, described by a differential equation of the form <img class="formulaInl" alt="$ \dot{x} = f(x,u,t) $" src="form_4.png"/> we wish to compute the linearized form of the system around an operating point <img class="formulaInl" alt="$ x=x_s $" src="form_5.png"/>, <img class="formulaInl" alt="$ u=u_s $" src="form_6.png"/>.</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \dot{x} = A(x_s, u_s) x + B(x_s, u_s) u \]" src="form_7.png"/>
</p>
<p>with the System's Jacobians with respect to state and input</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{aligned} A &amp;= \frac{df}{dx} |_{x=x_s, u=u_s} \\ B &amp;= \frac{df}{du} |_{x=x_s, u=u_s} \end{aligned} \]" src="form_8.png"/>
</p>
<p>As in the example above, we are left with different methods for computing the Jacobians. In the Control Toolbox the following methods are implemented for linearizing a ct::core::System.</p><ol type="1">
<li>Numerical Differentiation, see ct::core::SystemLinearizer</li>
<li>Automatic Differentiation, see ct::core::AutoDiffLinearizer</li>
<li>Auto-Diff Codegen, see ct::core::ADCodegenLinearizer</li>
</ol>
<p>Again, the same properties as above hold in terms of speed, accuracy, setup time etc. As an example on how to use these different classes, let's again look at a unit test, this time at ct_core/test/math/AutoDiffLinearizerTest.cpp. This unit test shows how to use numerical and automatic differentiation to compute the linearization.</p>
<div class="fragment"><div class="line"><span class="comment">/**********************************************************************************************************************</span></div><div class="line"><span class="comment">This file is part of the Control Toolbox (https://adrlab.bitbucket.io/ct), copyright by ETH Zurich, Google Inc.</span></div><div class="line"><span class="comment">Licensed under Apache2 license (see LICENSE file in main directory)</span></div><div class="line"><span class="comment">**********************************************************************************************************************/</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &lt;ct/core/core.h&gt;</span></div><div class="line"><span class="preprocessor">#include &quot;system/TestNonlinearSystem.h&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;system/TestDiscreteNonlinearSystem.h&quot;</span></div><div class="line"></div><div class="line"><span class="comment">// Bring in gtest</span></div><div class="line"><span class="preprocessor">#include &lt;gtest/gtest.h&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span>ct::core;</div><div class="line"><span class="keyword">using</span> std::shared_ptr;</div><div class="line"></div><div class="line"></div><div class="line">TEST(AutoDiffLinearizerTest, SystemLinearizerComparison)</div><div class="line">{</div><div class="line">    <span class="comment">// define the dimensions of the system</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">size_t</span> state_dim = TestNonlinearSystem::STATE_DIM;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">size_t</span> control_dim = TestNonlinearSystem::CONTROL_DIM;</div><div class="line"></div><div class="line">    <span class="comment">// typedefs for the auto-differentiable system</span></div><div class="line">    <span class="keyword">typedef</span> CppAD::AD&lt;double&gt; AD_Scalar;</div><div class="line">    <span class="keyword">typedef</span> tpl::TestNonlinearSystem&lt;AD_Scalar&gt; TestNonlinearSystemAD;</div><div class="line"></div><div class="line">    <span class="comment">// handy typedefs for the Jacobian</span></div><div class="line">    <span class="keyword">typedef</span> Eigen::Matrix&lt;double, state_dim, state_dim&gt; A_type;</div><div class="line">    <span class="keyword">typedef</span> Eigen::Matrix&lt;double, state_dim, control_dim&gt; B_type;</div><div class="line"></div><div class="line">    <span class="comment">// create two nonlinear systems, one regular one and one auto-differentiable</span></div><div class="line">    <span class="keywordtype">double</span> w_n = 100;</div><div class="line">    shared_ptr&lt;TestNonlinearSystem&gt; nonlinearSystem(<span class="keyword">new</span> TestNonlinearSystem(w_n));</div><div class="line">    shared_ptr&lt;TestNonlinearSystemAD&gt; nonlinearSystemAD(<span class="keyword">new</span> tpl::TestNonlinearSystem&lt;AD_Scalar&gt;(AD_Scalar(w_n)));</div><div class="line"></div><div class="line">    <span class="comment">// create a linearizer that applies numerical differentiation</span></div><div class="line">    SystemLinearizer&lt;state_dim, control_dim&gt; systemLinearizer(nonlinearSystem);</div><div class="line"></div><div class="line">    <span class="comment">// create a linearizer that uses codegeneration</span></div><div class="line">    AutoDiffLinearizer&lt;state_dim, control_dim&gt; adLinearizer(nonlinearSystemAD);</div><div class="line">    std::shared_ptr&lt;AutoDiffLinearizer&lt;state_dim, control_dim&gt;&gt; adLinearizerClone(adLinearizer.clone());</div><div class="line"></div><div class="line">    <span class="comment">// create state, control and time variables</span></div><div class="line">    StateVector&lt;TestNonlinearSystem::STATE_DIM&gt; x;</div><div class="line">    ControlVector&lt;TestNonlinearSystem::CONTROL_DIM&gt; u;</div><div class="line">    <span class="keywordtype">double</span> t = 0;</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; 1000; i++)</div><div class="line">    {</div><div class="line">        <span class="comment">// set a random state</span></div><div class="line">        x.setRandom();</div><div class="line">        u.setRandom();</div><div class="line"></div><div class="line">        <span class="comment">// use the numerical differentiation linearizer</span></div><div class="line">        A_type A_system = systemLinearizer.getDerivativeState(x, u, t);</div><div class="line">        B_type B_system = systemLinearizer.getDerivativeControl(x, u, t);</div><div class="line"></div><div class="line">        <span class="comment">// use the auto differentiation linearzier</span></div><div class="line">        A_type A_ad = adLinearizer.getDerivativeState(x, u, t);</div><div class="line">        B_type B_ad = adLinearizer.getDerivativeControl(x, u, t);</div><div class="line"></div><div class="line">        A_type A_adCloned = adLinearizerClone-&gt;getDerivativeState(x, u, t);</div><div class="line">        B_type B_adCloned = adLinearizerClone-&gt;getDerivativeControl(x, u, t);</div><div class="line"></div><div class="line">        <span class="comment">// verify the result</span></div><div class="line">        ASSERT_LT((A_system - A_ad).array().abs().maxCoeff(), 1e-5);</div><div class="line">        ASSERT_LT((B_system - B_ad).array().abs().maxCoeff(), 1e-5);</div><div class="line"></div><div class="line">        ASSERT_LT((A_system - A_adCloned).array().abs().maxCoeff(), 1e-5);</div><div class="line">        ASSERT_LT((B_system - B_adCloned).array().abs().maxCoeff(), 1e-5);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">TEST(AutoDiffDiscreteLinearizerTest, DiscreteSystemLinearizerComparison)</div><div class="line">{</div><div class="line">    <span class="comment">// define the dimensions of the system</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">size_t</span> state_dim = TestDiscreteNonlinearSystem::STATE_DIM;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">size_t</span> control_dim = TestDiscreteNonlinearSystem::CONTROL_DIM;</div><div class="line"></div><div class="line">    <span class="comment">// typedefs for the auto-differentiable system</span></div><div class="line">    <span class="keyword">typedef</span> CppAD::AD&lt;double&gt; AD_Scalar;</div><div class="line">    <span class="keyword">typedef</span> tpl::TestDiscreteNonlinearSystem&lt;AD_Scalar&gt; TestDiscreteNonlinearSystemAD;</div><div class="line"></div><div class="line">    <span class="comment">// handy typedefs for the Jacobian</span></div><div class="line">    <span class="keyword">typedef</span> StateMatrix&lt;state_dim, double&gt; A_type;</div><div class="line">    <span class="keyword">typedef</span> StateControlMatrix&lt;state_dim, control_dim, double&gt; B_type;</div><div class="line"></div><div class="line">    <span class="comment">// create two nonlinear systems, one regular one and one auto-differentiable</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">double</span> rate = 0.1;</div><div class="line">    shared_ptr&lt;TestDiscreteNonlinearSystem&gt; nonlinearSystem(<span class="keyword">new</span> TestDiscreteNonlinearSystem(rate));</div><div class="line">    shared_ptr&lt;TestDiscreteNonlinearSystemAD&gt; nonlinearSystemAD(</div><div class="line">        <span class="keyword">new</span> tpl::TestDiscreteNonlinearSystem&lt;AD_Scalar&gt;(AD_Scalar(rate)));</div><div class="line"></div><div class="line">    <span class="comment">// create a linearizer that applies numerical differentiation</span></div><div class="line">    DiscreteSystemLinearizer&lt;state_dim, control_dim&gt; systemLinearizer(nonlinearSystem);</div><div class="line"></div><div class="line">    <span class="comment">// create a linearizer that uses auto differentiation</span></div><div class="line">    DiscreteSystemLinearizerAD&lt;state_dim, control_dim&gt; adLinearizer(nonlinearSystemAD);</div><div class="line">    std::shared_ptr&lt;DiscreteSystemLinearizerAD&lt;state_dim, control_dim&gt;&gt; adLinearizerClone(adLinearizer.clone());</div><div class="line"></div><div class="line">    <span class="comment">// create state, control and time variables</span></div><div class="line">    StateVector&lt;TestNonlinearSystem::STATE_DIM&gt; x;</div><div class="line">    ControlVector&lt;TestNonlinearSystem::CONTROL_DIM&gt; u;</div><div class="line">    <span class="keywordtype">int</span> n = 0;</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; 1000; i++)</div><div class="line">    {</div><div class="line">        <span class="comment">// set a random state</span></div><div class="line">        x.setRandom();</div><div class="line">        u.setRandom();</div><div class="line"></div><div class="line">        <span class="comment">// use the numerical differentiation linearizer</span></div><div class="line">        A_type A_system = systemLinearizer.getDerivativeState(x, u, n);</div><div class="line">        B_type B_system = systemLinearizer.getDerivativeControl(x, u, n);</div><div class="line"></div><div class="line">        A_type A_system2;</div><div class="line">        B_type B_system2;</div><div class="line"></div><div class="line">        <span class="comment">// sanity check: compare getDerivtive* methods with getAandB</span></div><div class="line">        systemLinearizer.getAandB(x, u, x, n, 1, A_system2, B_system2);</div><div class="line">        ASSERT_LT((A_system - A_system2).array().abs().maxCoeff(), 1e-5);</div><div class="line">        ASSERT_LT((B_system - B_system2).array().abs().maxCoeff(), 1e-5);</div><div class="line"></div><div class="line">        <span class="comment">// analytic derivative</span></div><div class="line">        A_type A_system_analytic;</div><div class="line">        A_system_analytic &lt;&lt; 1.0 + rate * u(0), 0.0, x(1) * x(1), 2.0 * x(0) * x(1);</div><div class="line"></div><div class="line">        B_type B_system_analytic;</div><div class="line">        B_system_analytic &lt;&lt; rate * x(0), 0.0;</div><div class="line"></div><div class="line">        ASSERT_LT((A_system - A_system_analytic).array().abs().maxCoeff(), 1e-5);</div><div class="line">        ASSERT_LT((B_system - B_system_analytic).array().abs().maxCoeff(), 1e-5);</div><div class="line"></div><div class="line">        <span class="comment">// use the auto differentiation linearzier</span></div><div class="line">        A_type A_ad = adLinearizer.getDerivativeState(x, u, n);</div><div class="line">        B_type B_ad = adLinearizer.getDerivativeControl(x, u, n);</div><div class="line"></div><div class="line">        A_type A_adCloned = adLinearizerClone-&gt;getDerivativeState(x, u, n);</div><div class="line">        B_type B_adCloned = adLinearizerClone-&gt;getDerivativeControl(x, u, n);</div><div class="line"></div><div class="line">        <span class="comment">// verify the result</span></div><div class="line">        ASSERT_LT((A_system - A_ad).array().abs().maxCoeff(), 1e-5);</div><div class="line">        ASSERT_LT((B_system - B_ad).array().abs().maxCoeff(), 1e-5);</div><div class="line"></div><div class="line">        ASSERT_LT((A_system - A_adCloned).array().abs().maxCoeff(), 1e-5);</div><div class="line">        ASSERT_LT((B_system - B_adCloned).array().abs().maxCoeff(), 1e-5);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line">TEST(AutoDiffLinearizerTestMP, SystemLinearizerComparisonMP)</div><div class="line">{</div><div class="line">    <span class="comment">// define the dimensions of the system</span></div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">size_t</span> state_dim = TestNonlinearSystem::STATE_DIM;</div><div class="line">    <span class="keyword">const</span> <span class="keywordtype">size_t</span> control_dim = TestNonlinearSystem::CONTROL_DIM;</div><div class="line">    <span class="keyword">typedef</span> std::shared_ptr&lt;AutoDiffLinearizer&lt;state_dim, control_dim&gt;&gt; AdLinearizerPtr;</div><div class="line">    <span class="keyword">typedef</span> StateVector&lt;state_dim&gt; StateVector;</div><div class="line">    <span class="keyword">typedef</span> ControlVector&lt;control_dim&gt; ControlVector;</div><div class="line"></div><div class="line">    <span class="comment">// typedefs for the auto-differentiable system</span></div><div class="line">    <span class="keyword">typedef</span> CppAD::AD&lt;double&gt; AD_Scalar;</div><div class="line">    <span class="keyword">typedef</span> tpl::TestNonlinearSystem&lt;AD_Scalar&gt; TestNonlinearSystemAD;</div><div class="line"></div><div class="line">    <span class="comment">// handy typedefs for the Jacobian</span></div><div class="line">    <span class="keyword">typedef</span> Eigen::Matrix&lt;double, state_dim, state_dim&gt; A_type;</div><div class="line">    <span class="keyword">typedef</span> Eigen::Matrix&lt;double, state_dim, control_dim&gt; B_type;</div><div class="line"></div><div class="line">    <span class="comment">// create two nonlinear systems, one regular one and one auto-differentiable</span></div><div class="line">    <span class="keywordtype">double</span> w_n = 100;</div><div class="line">    shared_ptr&lt;TestNonlinearSystem&gt; nonlinearSystem(<span class="keyword">new</span> TestNonlinearSystem(w_n));</div><div class="line">    shared_ptr&lt;TestNonlinearSystemAD&gt; nonlinearSystemAD(<span class="keyword">new</span> tpl::TestNonlinearSystem&lt;AD_Scalar&gt;(AD_Scalar(w_n)));</div><div class="line"></div><div class="line">    <span class="comment">// create a linearizer that applies numerical differentiation</span></div><div class="line">    SystemLinearizer&lt;state_dim, control_dim&gt; systemLinearizer(nonlinearSystem);</div><div class="line">    AutoDiffLinearizer&lt;state_dim, control_dim&gt; adLinearizer(nonlinearSystemAD);</div><div class="line"></div><div class="line">    std::vector&lt;std::shared_ptr&lt;SystemLinearizer&lt;state_dim, control_dim&gt;&gt;&gt; systemLinearizers;</div><div class="line"></div><div class="line">    <span class="keywordtype">size_t</span> runs = 1000;</div><div class="line">    <span class="keywordtype">size_t</span> numThreads = 5;</div><div class="line"></div><div class="line">    <span class="comment">// The ad objects cannot yet be initialized here</span></div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; numThreads; ++i)</div><div class="line">        systemLinearizers.push_back(</div><div class="line">            std::shared_ptr&lt;SystemLinearizer&lt;state_dim, control_dim&gt;&gt;(systemLinearizer.clone()));</div><div class="line"></div><div class="line">    <span class="comment">// Count in the main thread</span></div><div class="line">    CppadParallel::initParallel(numThreads + 1);</div><div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> n = 0; n &lt; runs; ++n)</div><div class="line">    {</div><div class="line">        std::vector&lt;std::thread&gt; threads;</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; numThreads; ++i)</div><div class="line">        {</div><div class="line">            threads.push_back(std::thread([i, state_dim, control_dim, &amp;adLinearizer, &amp;systemLinearizers]() {</div><div class="line">                <span class="comment">// The ad objects are initialized here, because they need to be associated with the specfic thread number</span></div><div class="line">                AdLinearizerPtr adLinearizerLocal = AdLinearizerPtr(adLinearizer.clone());</div><div class="line"></div><div class="line">                StateVector x;</div><div class="line">                ControlVector u;</div><div class="line">                <span class="keywordtype">double</span> t = 0.0;</div><div class="line"></div><div class="line">                x.setRandom();</div><div class="line">                u.setRandom();</div><div class="line"></div><div class="line">                <span class="comment">// use the numerical differentiation linearizer</span></div><div class="line">                A_type A_system = systemLinearizers[i]-&gt;getDerivativeState(x, u, t);</div><div class="line">                B_type B_system = systemLinearizers[i]-&gt;getDerivativeControl(x, u, t);</div><div class="line"></div><div class="line">                <span class="comment">// use the auto differentiation linearzier</span></div><div class="line">                A_type A_ad = adLinearizerLocal-&gt;getDerivativeState(x, u, t);</div><div class="line">                B_type B_ad = adLinearizerLocal-&gt;getDerivativeControl(x, u, t);</div><div class="line"></div><div class="line">                <span class="comment">// verify the result</span></div><div class="line">                ASSERT_LT((A_system - A_ad).array().abs().maxCoeff(), 1e-5);</div><div class="line">                ASSERT_LT((B_system - B_ad).array().abs().maxCoeff(), 1e-5);</div><div class="line">            }));</div><div class="line">        }</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; thr : threads)</div><div class="line">            thr.join();</div><div class="line">    }</div><div class="line"></div><div class="line">    CppadParallel::resetParallel();</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv)</div><div class="line">{</div><div class="line">    testing::InitGoogleTest(&amp;argc, argv);</div><div class="line">    <span class="keywordflow">return</span> RUN_ALL_TESTS();</div><div class="line">}</div></div><!-- fragment --><p>For an example on how to use Auto-Diff Codegen to compute the linearization, see ADCodegenLinearizerTest.h</p>
<dl class="section note"><dt>Note</dt><dd>Both Auto-Diff and Auto-Diff Codegen require you to template your function on the scalar type. Please see the tutorial <a class="el" href="core_tut_linearization.html#core_tut_linearization_scalar_templating">Templating your System or Function on the Scalar Type</a> for tips and tricks on how to do this easily!</dd></dl>
<h1><a class="anchor" id="core_tut_linearization_scalar_templating"></a>
Templating your System or Function on the Scalar Type</h1>
<p>In order to make use of Auto-Differentiation, you need to template your system on the scalar type. This means Auto-Diff needs to be able to call your system function with a special type, rather than a regular float or double type. If your modelling framework does not support this natively (as often the case), here is a short guide on how to add Auto-Diff support. Luckily, the Eigen library already templates its type on the scalar type already. Thus, if you are using Eigen, this process is even easier.</p>
<p>There are different ways of templating your code on the scalar type. Here, we describe one of several options. Assume you have your class that contains your model/system:</p>
<div class="fragment"><div class="line"><span class="keyword">namespace </span>my_sys {</div><div class="line"></div><div class="line"><span class="keyword">class </span>MySystem : <span class="keyword">public</span> ct:core::ControlledSystem&lt;2, 1&gt; {</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="keywordtype">size_t</span> STATE_DIM = 2;</div><div class="line">    <span class="keywordtype">size_t</span> INPUT_DIM = 1;</div><div class="line"></div><div class="line">    <span class="keywordtype">void</span> computeControlledDynamics(<span class="keyword">const</span> StateVector&lt;STATE_DIM&gt;&amp; state,</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">double</span>&amp; t,</div><div class="line">        <span class="keyword">const</span> ControlVector&lt;CONTROL_DIM&gt;&amp; control,</div><div class="line">        StateVector&lt;STATE_DIM&gt;&amp; derivative) <span class="keyword">override</span>;</div><div class="line"></div><div class="line"> <span class="keyword">private</span>:</div><div class="line">    <span class="keywordtype">double</span> my_paramter_;</div><div class="line">};</div><div class="line"></div><div class="line">} <span class="comment">// namespace my_sys</span></div></div><!-- fragment --><p>The first step is to template your class on the scalar type. When doing so, we recommend moving your class to a new subnamespace (here called "tpl"). The reason to do so is that you can add a "using" directive in the original namespace, that defines your class with its original scalar type. In this way, all other code you might have written is not affected and continues to work. As a second step, you replace all double or floats or whatever scalar type you used before with the template parameter. CT types are already templated on scalar types, making your life much easier. The result would look something like this:</p>
<div class="fragment"><div class="line"><span class="keyword">namespace </span>my_sys {</div><div class="line"><span class="keyword">namespace </span>tpl {</div><div class="line"></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> SCALAR&gt;</div><div class="line"><span class="keyword">class </span>MySystem : ct::core::ControlledSystem&lt;2, 1, SCALAR&gt; {</div><div class="line">  <span class="keyword">public</span>:</div><div class="line">    <span class="keywordtype">size_t</span> STATE_DIM = 2;</div><div class="line">    <span class="keywordtype">size_t</span> INPUT_DIM = 1;</div><div class="line"></div><div class="line">    <span class="keywordtype">void</span> computeControlledDynamics(<span class="keyword">const</span> StateVector&lt;STATE_DIM, SCALAR&gt;&amp; state,</div><div class="line">        <span class="keyword">const</span> SCALAR&amp; t,</div><div class="line">        <span class="keyword">const</span> ControlVector&lt;CONTROL_DIM, SCALAR&gt;&amp; control,</div><div class="line">        StateVector&lt;STATE_DIM, SCALAR&gt;&amp; derivative) <span class="keyword">override</span>;</div><div class="line"></div><div class="line"> <span class="keyword">private</span>:</div><div class="line">    SCALAR my_paramter_;</div><div class="line">};</div><div class="line"></div><div class="line">} <span class="comment">// namespace tpl</span></div><div class="line"></div><div class="line"><span class="keyword">using</span> MySystem = tpl::MySystem&lt;double&gt;; <span class="comment">// this line ensures backwards compatibility of dependent code</span></div><div class="line"></div><div class="line">} <span class="comment">// namespace my_sys</span></div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Fixed quantities such as the state dimension obviously do not need to be type converted.</dd>
<dd>
It is not strictly necessary to change the parameter ("my_parameter_") to SCALAR type as well. However, you can then use Auto-Diff to derive e.g. your dynamics function by this parameter if you ever wanted to do parametric optimization or system identification. Cool eh? :)</dd>
<dd>
Since your class is templated now, make sure you move the implementation from the .cpp file to the .h file (or an implementation file that gets included in the .h file).</dd>
<dd>
In case your class is already templated (on anything really), one option is to add the scalar type to the list of templates and default it to whatever scalar type you used before.</dd></dl>
<p>There are some pitfalls when using Auto-Differentiation. Please read the notes below.</p>
<p>In order to make sure your class works with Auto-Differentiation, your code needs to comply with some restrictions: Ideally, your code should not contain branching, i.e. no if/else, switch or for loops that <b>depend</b> on an Auto-Diff scalar. While there are proper ways of dealing with branching you might not want to start out with it. Branching that depends only on paramters of which you do not want to take the derivative of is fine. Using mathematical functions or linear algebra: Functions such as std::sin, std::exp or inverses of Eigen matrices either do not support scalar types or have internal branching. Thus, they cannot be used. Thus, we provide traits that help you in this situation. These traits will select appropriate functions to call, depending on which SCALAR type is used. In case you called std::sin before, you should now call ct::core::internal::TraitSelector&lt;SCALAR&gt;::Trait::sin. In case e.g. SCALAR is a double type, this will call std::sin but for instances of the Auto-Diff scalar it will call the Auto-Diff compatible versions of sin.</p>
<p>Once the conversion is completed, you can follow the instructions above to compute Jacobians. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="getting_started.html">Getting Started</a></li><li class="navelem"><a class="el" href="core_tutorials.html">ct core Tutorials</a></li>
    <li class="footer">Generated on Sat Apr 27 2019 11:45:04 for ct by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
